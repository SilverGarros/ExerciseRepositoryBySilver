## 1 警告！！！此题有坑：模型使用样例中,如下

``` python

import torch
import torch.nn as nn

class TextClassifier(nn.Module):
    def __init__(self, vocab_size=1000, embed_dim=128, hidden_dim=512, num_classes=2):
        super(TextClassifier, self).__init__()

        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.rnn = nn.LSTM(embed_dim, hidden_dim)
        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, text):

        embedded = self.embedding(text)
        packed_output, (hidden, cell) = self.rnn(embedded)
        output = self.fc(hidden.squeeze(0))
        return output

model = TextClassifier()
model.load_state_dict(torch.load('model.pt'))
model.eval()
output = model(torch.ones([256, 1], dtype=torch.long))
print(output.detach().numpy().tolist())
# [[0.05428319424390793, 0.09556099772453308]]
```

model的输入应该为**[256, 1]**，数据类型为长整型(torch.long)的张量，但题目给的task.py 代码中进行测试转换后的ONNX格式模型的输入为`[101, 304, 993, 108,102]`，**[5,1]**维度的张量，所以应该对其进行**填零扩充至256位**后进行推理。

## 2.前置知识

[ONNX基础知识](https://zhuanlan.zhihu.com/p/686126692)

[Pytorch转ONNX](https://blog.csdn.net/superbinlovemiaomi/article/details/121344667)

## 3.题目要求

请在 `task.py` 文件中根据以下要求编写代码。

#### 3.1完成函数 convert

> 功能
>
> 将本任务提供的 pt 模型文件转换为 ONNX 格式。
>
> ONNX 模型文件保存在 `task.py` 文件同级目录下。
>
> ONNX 模型文件名为 `text_classifier.onnx`。

```python
def convert():
    # TODO
    model = TextClassifier()
    model.load_state_dict(torch.load('model.pt'))
    model.eval()

    dummy_input = torch.ones([256, 1],dtype=torch.long)
    # dummy_input 是一个 PyTorch 张量，它在这里被用作模型转换过程中的虚拟输入。
    # 这是因为 PyTorch 的 torch.onnx.export 函数需要一个实例输入张量来正确地推断 ONNX 图的形状。
    torch.onnx.export(model,dummy_input,'/home/project/text_classifier.onnx')
```



#### 3.2 完成函数 inference

> 功能
>
> 读取 ONNX 模型文件。
>
> 使用 ONNX 模型进行推理。
>
> 返回推理结果。
>
> - 参数
>   - model_path，字符串类型，ONNX 模型文件的绝对路径。
>   - input，整数列表类型，为待预测样本，示例如：[101, 304, 993, 1008,102]。
> - 返回值
>   - result，浮点数列表类型，为 ONNX 文件推理结果，示例如：[[0.53419, 0.44313]]。

```python
def inference(model_path, input):
    # TODO
    ort_session = ort.InferenceSession(model_path) #使用 ONNX 运行时加载 ONNX 模型。
    input_data = np.array(input,dtype=np.int64)# 将输入数据转换为 numpy 数组，数据类型设置为 int64。
    # ！！！将输入填充为256位的数据！！
    # 如果输入数据的长度小于 256，使用 0 填充输入数据，使其长度达到 256。然后将填充后的数据重塑为形状为 [256, 1] 的数组。
    if len(input_data) < 256:
        input_data = np.pad(input_data, (0, 256 - len(input_data)), 'constant', constant_values=0).reshape(256,1)
    print(input_data.shape)
	
    ort_inputs={ort_session.get_inputs()[0].name:input_data} # 准备模型的输入，其中键是模型的输入节点的名称，值是输入数据。
    ort_outs = ort_session.run(None,ort_inputs)# 使用 run 方法运行模型并获取输出。
    result = ort_outs[0]
    return result
```

## 4.完整代码

```python
#task-start
import numpy as np
import onnxruntime as ort
import torch
import torch.nn as nn


class TextClassifier(nn.Module):
    def __init__(self, vocab_size=1000, embed_dim=128, hidden_dim=512, num_classes=2):
        super(TextClassifier, self).__init__()

        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.rnn = nn.LSTM(embed_dim, hidden_dim)
        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, text):

        embedded = self.embedding(text)
        packed_output, (hidden, cell) = self.rnn(embedded)
        output = self.fc(hidden.squeeze(0))
        return output


def convert():
    # TODO
    model = TextClassifier()
    model.load_state_dict(torch.load('model.pt'))
    model.eval()

    dummy_input = torch.ones([256, 1],dtype=torch.long)
    torch.onnx.export(model,dummy_input,'/home/project/text_classifier.onnx')


def inference(model_path, input):
    # TODO
    ort_session = ort.InferenceSession(model_path)
    input_data = np.array(input,dtype=np.int64)
    # ！！！将输入填充为256位的数据！！
    if len(input_data) < 256:
        input_data = np.pad(input_data, (0, 256 - len(input_data)), 'constant', constant_values=0).reshape(256,1)
    print(input_data.shape)

    ort_inputs={ort_session.get_inputs()[0].name:input_data}
    ort_outs = ort_session.run(None,ort_inputs)
    result = ort_outs[0]
    return result


def main():
    convert()
    result = inference('/home/project/text_classifier.onnx', [101, 304, 993, 108,102])
    print(result)


if __name__ == '__main__':
    main()
```

