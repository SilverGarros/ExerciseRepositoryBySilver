## 1.相关知识

#### 1.1 Word2Vec

**Word2Vec**是google在2013年推出的一个NLP工具，它的特点是能够将单词转化为向量来表示，这样词与词之间就可以定量的去度量他们之间的关系，挖掘词之间的联系。

#### 1.2 gensim库及其Word2Vec组件

**Genism**是一款开源的第三方Python工具包，用于从原始的非结构化的文本中，无监督地学习到文本隐层的主题向量表达。
它支持包括TF-IDF，LSA，LDA，和word2vec在内的多种主题模型算法，
支持流式训练，并提供了诸如相似度计算，信息检索等一些常用任务的API接口

[【NLP】4 gensim word2vec库入门——官方手册embeddings和KeyedVectors_models.word2vec官方文档-CSDN博客](https://blog.csdn.net/qq_41897800/article/details/113793507)

```python
from gensim.models import Word2Vec

model = Word2Vec(sentences=common_texts, size=100, window=5, min_count=1, workers=4)
model.save("word2vec.model")
# 加载Word2Vec模型
model=Word2Vec.load("word2vec.model")
print(model.train([["hello", "world"]], total_examples=1, epochs=1))
# (0,2)
# 获取单词的numpy向量，wv 属性用于访问和操作词向量。
vector = model.wv['computer']
```

## 2.题目要求

#### 2.1 完成函数get_w2v

> 函数 **get_w2v**
> 功能：调用训练好的词向量模型，获取词的词向量。
> 参数：
> word ：string，一个词。
> 返回值：
> word_vector：如果输入词在模型词汇表中，则**返回一个 numpy.ndarray 类型的词向量**，如果不在，则返回 None

```python
def get_w2v(word):
    #TODO
    # print(word)
    try:
        # 在 gensim 的 Word2Vec 模型中，wv 属性用于访问和操作词向量。
        # 例如，`model.wv['word']` 来获取 'word' 的向量，
        # 或者使用 `model.wv.most_similar('word')` 来获取与 'word' 最相似的词。
        #    >>> vector = model.wv['computer']  # get numpy vector of a word
        #    >>> sims = model.wv.most_similar('computer', topn=10)  # get other similar words
        word_vector=W2V_MODEL.wv[word]
        # print(type(word_vector))
        # '''<class 'numpy.ndarray'>'''
        return word_vector
    except KeyError:
        return None
```

#### 2.2 完成函数get_sentence_vector
>函数 **get_sentence_vector**
>功能：获取句子的向量表示，具体方法为：
>**遍历句子中的每一个词，调用 get_w2v 函数，获取词向量表示。**
>**计算所有词向量的平均值作为句子的向量表示。如果一个句子中所有词向量均为 None，则返回一个形状为 (100,) 的全零向量。**
>参数：
>sentence ：list，一个经分词处理后的句子。
>返回值：
>sentence_vector：**numpy.ndarray**，句向量。如果句子中的词语**没有对应的词向量，则返回一个全零向量**。

```python
def get_sentence_vector(sentence):
    
    #TODO
    Word_Vectors = []
    for word in sentence:
        Word_Vector = get_w2v(word)
        print(word)
        print(Word_Vector)
        if Word_Vector is not None:
            Word_Vector.append(Word_Vector)
    # 在 Word_Vectors []中至少得有一个词向量时计算所有词向量的平均值，/
    # 得到句子向量，如果 Word_Vectors 为空，则返回一个全零向量 
    if Word_Vectors:
        sentence_vector = np.mean(Word_Vector,axis=0)
    else:
        sentence_vector = np.zeros(100)
    return sentence_vector
```

## 3.参考代码

```python 
import jieba
import numpy as np
from gensim.models import Word2Vec
from sklearn.metrics.pairwise import cosine_similarity

w2v_file_path = "word2vec_model.bin"
W2V_MODEL= Word2Vec.load(w2v_file_path)
W2V_SIZE = 100

def get_w2v(word):
    #TODO
    # print(word)
    try:
        # 在 gensim 的 Word2Vec 模型中，wv 属性用于访问和操作词向量。
        # 例如，`model.wv['word']` 来获取 'word' 的向量，
        # 或者使用 `model.wv.most_similar('word')` 来获取与 'word' 最相似的词。
        #    >>> vector = model.wv['computer']  # get numpy vector of a word
        #    >>> sims = model.wv.most_similar('computer', topn=10)  # get other similar words
        word_vector=W2V_MODEL.wv[word]
        print(type(W2V_MODEL.wv[word]))
        return word_vector
    except KeyError:
        return None



def get_sentence_vector(sentence):

    #TODO
    Word_Vectors = []
    for word in sentence:
        Word_Vector=get_w2v(word)
        # print(type(Word_Vector))
        # print(Word_Vector)
        if Word_Vector is not None:
            Word_Vectors.append(Word_Vector)
       # 在 Word_Vectors []中至少得有一个词向量时计算所有词向量的平均值，/
       # 得到句子向量，如果 Word_Vectors 为空，则返回一个全零向量 
    if Word_Vectors:
        sentence_vector = np.mean(Word_Vectors,axis=0)
    else:
        sentence_vector = np.zeros(100)
    return sentence_vector


def get_similarity(array1, array2):
    array1_2d = np.reshape(array1, (1, -1))
    array2_2d = np.reshape(array2, (1, -1))
    similarity = cosine_similarity(array1_2d, array2_2d)[0][0]
    return similarity

def main():
    
    # 测试两个句子
    sentence1 = '我不喜欢看新闻。'
    sentence2 = '我觉得新闻不好看。'
    sentence_split1 = jieba.lcut(sentence1)
    sentence_split2 = jieba.lcut(sentence2)
    # 获取句子的句向量
    sentence1_vector = get_sentence_vector(sentence_split1)
    sentence2_vector = get_sentence_vector(sentence_split2)
    # 计算句子的相似度
    similarity = get_similarity(sentence1_vector, sentence2_vector)
    print(similarity) 

if __name__ == '__main__':
    main()
```